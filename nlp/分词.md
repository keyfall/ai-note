前向最大匹配算法
1.设定一个max_len
2.对要分词的内容使用max_len长度分隔，进行从词典库中查找是否有对应的词
3.有就从此处截断，没有就使用max_len-1，重新进行第2步
![[Pasted image 20240506103715.png]]


后向最大匹配算法
1.从后开始分割
2.分割出来后的词，如果没有匹配，减的时候会从头减少，不是从最后面减，
比如“经常有意见”，前向减了之后会是"经常有意",后向减了之后为“常有意见”
![[Pasted image 20240506105629.png]]

最大匹配算法的缺点
![[Pasted image 20240506105717.png]]

分词语义考虑(歧义)

把所有可能得分词组合生成出来，交给语义模型评分，选择最高的
语义模型从训练语句(可能是1本书)中去获取内容
得到每个词出现的比例，然后把每个分词的比例相乘，得到分数
优化:如果得到的小数数值超过了范围，就会报错，所以一般不使用乘法，而使用log，那么每个分词就不是相乘，而是log比例相加
![[Pasted image 20240506112426.png]]
![[Pasted image 20240506113004.png]]

unigram lm(提高解决歧义的能力)
1.从左到右一个一个词分割，得到max_len+1个节点
2.从第一个节点开始往前计算，根据词典库找前面是否有不同的词(比如“长江大桥”，可能词典库有"长江"，"大桥"，"长江大桥",然后进行比较，哪个概率更高)
3.结果前面的节点已经是最好的概率了,后面直接取值就可以
![[Pasted image 20240506145551.png]]