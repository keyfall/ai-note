GoogLeNet 的主要设计目标是在不显著增加计算成本的前提下，提高网络的深度和宽度，从而提高模型的准确率。
![[Pasted image 20250312093006.png]]
#### 结构
- 初始层
	- 卷积层：GoogLeNet 开始于一个 7x7 的卷积层，通常带有步幅为 2，用于初步提取图像中的基本特征。
	- 最大池化层：紧随其后的是一个 3x3 的最大池化层，步幅为 2，用于减小特征图的尺寸，降低计算量。
	- 卷积层：之后是两个连续的 3x3 卷积层，用于进一步特征提取。
	- 最大池化层：再次进行最大池化，继续减小特征图的尺寸。
- Inception 模块：GoogLeNet 的核心是 Inception 模块，它们通常在初始层之后被多次重复。一个典型的 Inception 模块包含以下部分：
	- 1x1 卷积：用于降维，减少后续计算的成本。
	- 3x3 卷积：用于提取局部特征，通常在 1x1 卷积之后。
	- 5x5 卷积：用于捕获更大范围的特征，同样在 1x1 卷积之后。
	- 最大池化：用于捕捉图像中的重要特征，同时在池化之后使用 1x1 卷积以保持通道数。
	- depthconcat：拼接层，所有这些操作的输出会被拼接在一起，形成 Inception 模块的输出。
- 辅助分类器：GoogLeNet 在中间部分包含一到两个辅助分类器，它们在训练期间提供额外的监督信号，帮助网络学习更加鲁棒的特征表示
	- 平均池化层
	- 一个或多个 1x1 卷积层
	- 全连接层
	- softmax 分类层
- 输出层
	- 全局平均池化层：来将特征图转换为固定长度的向量
	- 全连接层
	- softmax 分类层：用于生成各个类别的概率预测。

#### 特点
- Inception 模块：
	- 多尺度特征提取：Inception 模块设计用于并行处理信息，通过在同一层中使用不同大小的卷积核（如 1x1、3x3、5x5）和最大池化，能够捕捉到不同尺度的特征。
	- 降维机制：每个卷积层之前会有一个1x1的卷积层，用于降维，减少计算成本，同时学习通道之间的关系。
- 全局平均池化：全局平均池化层来取代传统的全连接层，这不仅减少了参数量，还避免了过拟合，同时加快了训练速度。
- 辅助分类器：在训练模型时，将两个辅助分类器的损失乘以权重（论文中是 0.3）加到网络的整体损失上，再进行反向传播，为深层网络提供了额外的监督信号，有助于缓解梯度消失问题，使深层网络更容易训练。

#### 优点
- 高效计算：因为并行使用不同的卷积核，再通道维度上拼接结果
- 多尺度特征提取：同时捕捉输入数据的不同尺度的信息，从而提高了模型对各种类型特征的表达能力。可以解决物体识别的难度
- 缓解梯度消失：因为辅助分类器，训练过程中，会将辅助分类器的损失乘以权重加到网络的整体损失中，缓解梯度消失(事实证明影响不大)
- 灵活性：通过改变卷积核的大小或数量来适应不同的计算资源限制

#### 缺点
- 计算资源大