#### SFT监督微调：
- 原理：在源数据集上训练一个源模型，复制一份作为目标模型，把该模型的输出层的输出大小换为目标数据集类别个数，并初始化输出层的参数，再在目标数据集上进行微调训练
- 优点：简单易用，通用性强
- 缺点：高质量标注数据
####  LoRA低秩适应：
- 原理：冻结预训练模型的权重参数，在模型中加入额外的网络层，并只训练这些新增的网络层参数
- 优点：
	- 灵活性强：对于不同的任务，只需要替换对应的低秩增量
	- 不会遗忘：由于原始权重参数保持不变，对预训练知识保留更好
	- 计算成本低
- 缺点：
	- 复杂度较高
	- 编程任务，复杂度高的任务效果不如全量微调
#### prefix-tuning微调
- 原理：模型中加入prefix,微调时只优化这一小段参数
- 优点：
	- 效率高
	- 灵活性强：只需要为不同的下游任务设计特定的前缀
	- 良好的泛化能力
- 缺点：
	- 前缀设计麻烦
	- 效果依赖于预训练模型质量
#### P-tuning v1微调
- 原理：模型中加入prompt,微调时只优化这一小段参数
- 优点：
	- 效率高
	- 灵活性强：只需要为不同的下游任务设计特定的前缀
	- 良好的泛化能力
- 缺点：
	- 对于小模型，效果差
#### prefix-tuning微调
- 原理：模型中加入prefix,微调时只优化这一小段参数
- 优点：
	- 效率高
	- 灵活性强：只需要为不同的下游任务设计特定的前缀
	- 良好的泛化能力
- 缺点：
	- 前缀设计麻烦
	- 效果依赖于预训练模型质量